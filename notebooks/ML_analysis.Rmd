---
title: "Machine Learning Approaches to Dissect Hybrid and Vaccine-Induced Immunity"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Import Required Libraries

```{r message=FALSE, warning=FALSE}
# Load necessary libraries
requiredPackages <- c('mclust', 'umap', 'Rtsne', 'ggplot2', 'fpc', 
                      'caret', 'dplyr', 'foreach', 'doParallel', 'MLmetrics')
for(p in requiredPackages){
  if(!require(p, character.only = TRUE)) install.packages(p)
  library(p, character.only = TRUE)
}
```

## **Part 1: Dimensionality Reduction and Clustering**

#### Load and Explore Data

```{r}
set.seed(983) 
# Load the synthetic dataset
load("../data/synth1.rda")
str(synth1)  
summary(synth1)
```

#### **UMAP for Dimensionality Reduction**

```{r message=FALSE, warning=FALSE}
# Apply UMAP on the dataset, excluding the first column 
# (assumed to be Infectious status)
set.seed(289) 
um <- umap::umap(synth1[,-c(1)], method = 'umap-learn', preserve.seed = T)

# Convert UMAP results into a data frame
umap_df <- data.frame(um$layout)
umap_df$Group <- synth1$Infection_0_1pre_2post
umap_df$ID <- rownames(umap_df) 

# Plot UMAP projection
ggplot(umap_df, aes(x = X1, y = X2, color = Group)) + 
  geom_point(size = 3) +
  scale_color_manual(labels = c("No Infection", "Infection pre-boost", 
                                "Infection post-boost"),
                     values = c("#66a182", "#2e4057", "#edae49")) +
  labs(x = 'UMAP 1', y = 'UMAP 2', title = 'Dimensionality Reduction (UMAP)') +
  theme_minimal()
```

#### **Clustering with Gaussian Mixture Model (GMM)**

```{r}
# Clustering with Gaussian Mixture Model (GMM) on UMAP-reduced data (unsupervised)
um_gmm = mclust::Mclust(umap_df[, c(1, 2)]) 

# Print summary of clustering results
summary(um_gmm)

# Plot the clustering results
plot(um_gmm, "classification") 
plot(um_gmm, "density")
```

#### **t-SNE for Dimensionality Reduction**

```{r}
# Apply t-SNE on the dataset, excluding the first column 
# (assumed to be Infectious status)
set.seed(7567)
tsne <- Rtsne::Rtsne(synth1[, -c(1)], perplexity = 38, normalize=FALSE, theta = 0.5)

# Convert t-SNE results into a data frame
tsne_df <- data.frame(tsne$Y)
tsne_df$Group <- synth1$Infection_0_1pre_2post
tsne_df$ID <- rownames(tsne_df)

# Plot t-SNE projection
ggplot(tsne_df, aes(x = X1, y = X2, color = Group)) +
  geom_point(size = 3) +
  scale_color_manual(labels = c("No Infection", "Infection pre-boost", 
                                "Infection post-boost"),
                     values = c("#66a182", "#2e4057", "#edae49")) +
  labs(x = 't-SNE 1', y = 't-SNE 2', title = 'Dimensionality Reduction (t-SNE)') +
  theme_minimal()
```

#### **Clustering with Gaussian Mixture Model (GMM)**

```{r}
# Clustering with Gaussian Mixture Model (GMM) on t-SNE-reduced data (unsupervised)
t_gmm <- mclust::Mclust(tsne_df[, c(1, 2)])

# Print summary of clustering results
summary(t_gmm)

# Plot the clustering results
plot(t_gmm, "classification")
plot(t_gmm, "density")
```

#### **Clustering Evaluation: Within-cluster Sum of Squares & Silhouette Score**

```{r}
# Compute clustering statistics for UMAP-based clustering
cs_um_gmm <- fpc::cluster.stats(dist(umap_df[1:2]), um_gmm$classification)
stats_um_gmm <- cs_um_gmm[c("within.cluster.ss","avg.silwidth")]

# Compute clustering statistics for t-SNE-based clustering
cs_ts_gmm <- fpc::cluster.stats(dist(tsne_df[1:2]), t_gmm$classification)
stats_t_gmm <- cs_ts_gmm[c("within.cluster.ss","avg.silwidth")]

# Combine statistics and print Comparison
stats <- rbind(stats_um_gmm, stats_t_gmm)
rownames(stats) <- c("UMAP", "t-SNE")
stats <- as.data.frame(stats)
stats
```

------------------------------------------------------------------------

## **Part 2: Unaware Infection Prediction (Classification Task)**

#### **Load and Preprocess Data**

```{r}
# Load the labeled synthetic dataset (synth2)
load("../data/synth2.rda")

# Ensure the target variable is a factor
synth2$Class <- as.factor(synth2$Class)

# Display basic dataset structure and summary
str(synth2)
summary(synth2)
```

#### **Machine Learning Models Construction**

```{r}
# Set a global seed
set.seed(1058) 

# Create 5 cross-validation folds to use for all models
cv_folds <- caret::createFolds(synth2$Class, k = 5, returnTrain = TRUE)

# Define training control settings
control <- caret::trainControl(
  method = "cv", number = 5, 
  classProbs = TRUE, 
  summaryFunction = multiClassSummary, 
  verboseIter = TRUE, 
  index = cv_folds
)
```

```{r}
# Define a function for hyper parameter tuning and training models
train_model <- function(method, tL) {
  caret::train(Class ~ ., data = synth2, method = method, 
               trControl = control, tuneLength = tL)
}

# Train models with hyperparameter tuning
knn_model <- train_model("knn", tL = 5)
rf_model  <- train_model("rf", tL = 5)
svm_model <- train_model("svmRadial", tL = 5)
```

#### **Model Performance Evaluation**

```{r}
# Collect and compare model results
results <- resamples(list(kNN = knn_model, RF = rf_model, SVM = svm_model))

# Select metrics of interest
selected_metrics <- results$values %>% 
  select(contains(c("Accuracy", "Precision", "Recall", "F1")))

# Display performance summary
summary(selected_metrics)

# Visualization of model performance
bwplot(results)
dotplot(results)
```

#### Variable Importance Analysis

```{r warning=FALSE}
# Variable Importance analysis
# Define a function to compute permutation-based feature importance for SVM and k-NN
permute_importance <- function(model, data, target_col, metric = "Accuracy", 
                               n_permutations = 10, parallel = TRUE) {
  set.seed(1848)
  y <- data[[target_col]]
  if (!is.factor(y)) y <- as.factor(y)  # Converte il target in fattore se necessario
  X <- data[, colnames(data) != target_col, drop = FALSE]
  
  # Check input data
  stopifnot(is.data.frame(data))
  stopifnot(target_col %in% colnames(data))
  stopifnot(nrow(data) > 10) 
  
  # Compute original accuracy
  original_preds <- predict(model, newdata = X)
  if (is.numeric(original_preds)) {
    original_preds <- ifelse(original_preds > 0.5, levels(y)[2], levels(y)[1])}
  original_acc <- mean(original_preds == y)
  
  # Prepare data frame to store importances
  importances <- data.frame(Feature = colnames(X), Importance = 0)
  
  # Allow parallel computation
  if (parallel) {
    registerDoParallel(cores = detectCores() - 1)}
  
  # Loop on each feature and compute importances
  results <- foreach(feature = colnames(X), .combine = rbind, .packages = "caret") %dopar% {
    acc_drops <- numeric(n_permutations)
    
    for (i in 1:n_permutations) {
      X_permuted <- X
      X_permuted[[feature]] <- sample(na.omit(X_permuted[[feature]]), replace = TRUE)
      
      permuted_preds <- predict(model, newdata = X_permuted)
      permuted_acc <- mean(permuted_preds == y)
      
      acc_drops[i] <- original_acc - permuted_acc}
    data.frame(Feature = feature, Importance = median(acc_drops))}
  
  # End parallel computation
  if (parallel) {
    stopImplicitCluster()}
  
  # Organize results
  results <- results[order(-results$Importance), ]
  
  # Plot importances
  p <- ggplot(results, aes(x = reorder(Feature, Importance), y = Importance)) +
    geom_col(fill = "steelblue") +
    coord_flip() +
    labs(title = "Feature Importance via Permutation",
         x = "Feature",
         y = "Importance (Drop in Accuracy)") +
    theme_minimal()
  print(p)
  
  return(results)
}

# Compute permutation-based importances for SVM-Radial
importance_svm <- permute_importance(svm_model, synth2, "Class", metric = "Accuracy", n_permutations = 10)
print(importance_svm)
# Compute permutation-based importances for k-NN
importance_knn <- permute_importance(knn_model, synth2, "Class", metric = "Accuracy", n_permutations = 10)
print(importance_knn)
# Compute vip based importances for Random Forest
importance_rf <- caret::varImp(rf_model, scale = TRUE)
importance_rf <- importance_rf$importance
importance_rf$Feature <- rownames(importance_rf)
ggplot(importance_rf, aes(x = reorder(Feature, Overall), y = Overall)) +
  geom_col(fill = "steelblue") +
  coord_flip() +
  labs(title = "Feature Importance via Permutation",
         x = "Feature",
         y = "Importance (Drop in Accuracy)") +
    theme_minimal()
print(importance_rf)
```

#### **Model Application: Prediction on Unlabelled Data**

```{r}
# Load synthetic unlabeled data (synth3)
load("../data/synth3.rda")

# Ensure feature consistency between synth2 and synth3
common_features <- intersect(names(synth2), names(synth3))
synth3 <- synth3[, common_features, drop = FALSE]

# Make predictions using trained models
synth3$kNN <- predict(knn_model, synth3)
synth3$RF  <- predict(rf_model, synth3)
synth3$SVM <- predict(svm_model, synth3)

# Compare model predictions
table(synth3$kNN)
table(synth3$RF)
table(synth3$SVM)
```

Session Informations

```{r}
sessionInfo()
```
